{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center>Digital Image Processing - Problem Set 4</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Student Names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This Problem Set covers the topics of Morphological operations, Region filling, Canny edge detection, Hough Transform, Thresholding, Watershed segmentation, $k$-means segmentation.<br>\n",
    "\n",
    "Your solutions to the following problems should include commented source code and a short description of each function. You should test your functions with several input images, besides the ones provided here. Include the input and output images that you used for experimentation. Analyze your results. If you discover something interesting, let us know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that performs the following sequence of morphological operations on a binary image and displays the intermediate and final results.\n",
    "\n",
    "1. Create a square-shaped structuring element of size 3 by 3.\n",
    "2. Erode the input image.\n",
    "3. Dilate the result of b.\n",
    "4. Dilate the result of c.\n",
    "5. Erode the result of d.\n",
    "\n",
    "Write a second function that performs the following operations and displays the intermediate and final results.\n",
    "\n",
    "1. Create a square-shaped structuring element of size 3 by 3.\n",
    "2. Perform opening of the input image.\n",
    "3. Compute the closing of the result from b.\n",
    "\n",
    "Apply both functions to the image <tt>noisy_fingerprint.jpg</tt>. Discuss the differences and similarities between the final results of using both functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that implements the region filling function discussed in class.\n",
    "In this function you will need to use an interactive plot, so we need to disable <tt>inline</tt> plotting. This can be done with the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The algorithm should proceed as follows:\n",
    "\n",
    "1. Open and display the input binary image.\n",
    "2. Using the <tt>plt.ginput</tt> function, specify a pixel within the region that you want to fill. Record the $(x, y)$ coordinate of the selected pixel.\n",
    "3. Generate $X_0$, a binary image whose size is equal to the size of the input image. The pixel at the coordinate selected in the previous step should be set to 1, all other pixels should be set to zero.\n",
    "4. Compute $X_k$ according to the following equation. Repeat until convergence, i.e. $X_k = X_{k-1}$\n",
    "\\begin{equation}\n",
    "X_k=(X_{k-1} ⊕ B) ∩ A^c\n",
    "\\end{equation}\n",
    "\n",
    "5. Compute the union between the final $X_k$ and the original image to fill the region.\n",
    "\n",
    "Apply your function to the image <tt>spheres.jpg</tt> to fill in all the black circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f7a46854f50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from Tkinter import *\n",
    "\n",
    "def reg_filling(src):\n",
    "    fig = plt.figure();\n",
    "    plt.imshow(src,cmap='gray')\n",
    "    plt.title('Select coordinate')\n",
    "    coord= plt.ginput(1)  #Specify coordinate in image\n",
    "    xcoord= int(round(coord[0][0]));ycoord=int(round(coord[0][1])) #Separate both x and y coordinates\n",
    "    X = np.zeros((src.shape[0], src.shape[1]),dtype=np.uint8) #This is X0\n",
    "    X[ycoord,xcoord]=255 #Replace matrix with coordinates given in plt.ginput\n",
    "    B = 255*cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3)).astype(np.uint8)  #Define structuring element \n",
    "    A = src  #A is the image\n",
    "    A_C= cv2.bitwise_not(A)  #Complement\n",
    "    #Start operation\n",
    "    x_prev = X[:,:]  #Copy of X (X(k-1))\n",
    "    X = cv2.dilate(X,B,iterations=1)\n",
    "    X = np.bitwise_and(X,A_C)  #Xk\n",
    "    cont = 0\n",
    "    while(not(np.array_equal(x_prev,X))):  #Loop until convergence (In this case x_final = X)\n",
    "        x_prev = X[:,:]\n",
    "        X = cv2.dilate(X,B,iterations =1)\n",
    "        X = np.bitwise_and(X,A_C)\n",
    "        cont +=1\n",
    "    plt.close(fig)\n",
    "    fig1 = plt.figure()\n",
    "    plt.imshow(X,cmap='gray')\n",
    "    plt.show()\n",
    "    imgsal = np.bitwise_or(X,A)\n",
    "    plt.close(fig1)\n",
    "    return imgsal\n",
    "\n",
    "\n",
    "def exit():\n",
    "    root.destroy()\n",
    "#Tk interface to specify number of holes to be filled\n",
    "root = Tk()\n",
    "root.minsize(width=300, height=200)\n",
    "r = Label (root, text= \"¿Cuántas veces desea rellenar?\")\n",
    "r.place(relx=0.5, rely=0.25, anchor=CENTER)\n",
    "r1 = Label (root, text= \"Recommended: 17\")\n",
    "r1.place(relx=0.5, rely=0.375, anchor=CENTER)\n",
    "text_entered = StringVar()\n",
    "e = Entry(root, textvariable=text_entered)\n",
    "e.place(relx=0.5, rely=0.5, anchor=CENTER)\n",
    "\n",
    "button = Button(root,text=\"Close\",command=exit)\n",
    "button.place(relx=0.5, rely=0.75, anchor=CENTER)\n",
    "\n",
    "root.mainloop()\n",
    "src = cv2.imread('spheres.jpg',0)\n",
    "global text_entered\n",
    "content = text_entered.get()\n",
    "filled_img = reg_filling(src)\n",
    "\n",
    "    \n",
    "for i in range(int(content)-1):\n",
    "    filled_img = reg_filling(filled_img)\n",
    "orig = plt.figure();    \n",
    "plt.imshow(src,cmap='gray')\n",
    "plt.title('Original image')\n",
    "plt.figure();\n",
    "plt.imshow(filled_img,cmap='gray')\n",
    "plt.title('Final image with holes filled') \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Descripción de la función desarrollada:</h3>    \n",
    "<p style=\"text-align:justify\">La función reg_filling desarrollada en este inciso recibe como parámetro la imagen a la cual se le desea rellenar los vacíos o huecos y retorna una imagen con los vacíos o huecos rellenados. El número de vacíos a rellenar es especificado a través de una interfaz de la libreria Tkinter.</p>\n",
    "\n",
    "<h3>- Descripción de las funciones de librerías utilizadas:</h3>\n",
    "<p style=\"text-align:justify\">Para el desarrollo de este inciso se utilizaron las librerias OPENCV, Matplotlib y Numpy a través de las cuales se emplearon distintas funciones de las que se puede resaltar ginput() mediante la cual es posible capturar las coordenadas de una figura en las cuales se presiona click. El próposito de utilizar esta función es en este caso el de especificar la coordenada del vacío o hueco que se desea rellenar. Esta función recibe como parámetro de entrada el número de clicks que se van a grabar por lo que en este caso se especificó el número 1 debido a que solo se registrará una coordenada. Cabe destacar que para utilizar esta función fue necesario desactivar el modo \"inline plotting\" de la librería matplotlib y se decidió utilizar Qt debido a que ya se contaba con esta librería adicional a su facilidad de uso. Adicionalmente, se utilizó la función getStructuringElement() de la librería OpenCV la cual recibe como parámetro de entrada la forma del elemento estructurante a definir. En este caso se definió un elemento estructurante en forma de cruz y de tamaño 3x3. Para definir la forma de cruz de este elemento estructurante se utilizó la funcion MORPH_CROSS de la librería openCV.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Connected component labeling (also known as connected component analysis, blob extraction, region labeling, blob discovery, or region extraction) is an algorithm that uniquely labels connected components. The definition of connected components depends on the type of pixel adjacency used (pixel adjacency is defined and described in the book). In this problem, we will look at how the result of a connected component labeling algorithm changes when using 4-adjacency or 8-adjacency.\n",
    "\n",
    "Write a function, <tt>labelConnectedComponents</tt>, which identifies and labels each connected component in a binary image. The function should take as an input the kind of adjacency to be used (either 4-adjacency or 8-adjacency). The function should also display the resulting connected components as shown below (particular coloring may differ). Apply this function to the images crosses.gif and chessboard.gif. Compare the connected components obtained when using 4-adjacency against those obtained when using 8-adjacency. Please comment your results: are these what you expected?\n",
    "\n",
    "<b>Hint</b>: Use the functions <tt>cv2.findContours</tt> and <tt>cv2.drawContours</tt>. The following Wikipedia article is also a useful reference:\n",
    "http://en.wikipedia.org/wiki/Connected_Component_Labeling\n",
    "\n",
    "<img src=\"files/crosses.png\"/>\n",
    "<img src=\"files/connected.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The blog ‘Steve on Image Processing’ contains useful information about image processing with MATLAB. One of Steve’s posts talks about using morphological operations to identify characters containing a tall vertical segment. The post is at:\n",
    "http://blogs.mathworks.com/steve/2008/07/14/opening-by-reconstruction/\n",
    "\n",
    "Replicate the results with Python and OpenCV. You may find that the functions <tt>cv2.findContours</tt> and <tt>cv2.floodFill</tt> are useful for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that detects edges in an image using Canny’s method, which is available in the function <tt>cv2.Canny</tt>.\n",
    "Your function should first smooth the image using a Guassian filter, which you can do with <tt>cv2.GaussianBlur</tt>.\n",
    "Try out Canny's method with different sizes the smoothing kernel and analyze the results.\n",
    "Also, try changing the thresholds in the edge detection process. What are the effects of each parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that uses the Hough Transform algorithm for line detection. You can use the implementation available in OpenCV <tt>cv2.HoughLines</tt> in your function. Note that this function returns lines in the $(\\rho, \\theta)$ space, so you need to perform the appropiate conversions before plotting them.\n",
    "\n",
    "Run the line detection function on an edge map obtained using Canny's method. Display the detected lines on top of the input image. You should use several images for your tests, including <tt>building.jpg</tt>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that implements a simple adaptive thresholding algorithm as described below:\n",
    "\n",
    "1. Select an initial estimate for $T$. A good initial value for $T$ would be equal to the average of the maximum and minimum intensity value of the image.\n",
    "2. Threshold the image using $T$. This produces two groups: $G_1$, with pixels whose intensity is equal or less than $T$; and $G_2$, with pixels whose intensity is greater than $T$.\n",
    "3. Compute the intensity averages $\\mu_1$ and $\\mu_2$ for the pixels in regions $G_1$ and $G_2$.\n",
    "4. Compute a new threshold value\n",
    "\\begin{equation}\n",
    "T=\\frac{\\mu_1 + \\mu_2}{2}\n",
    "\\end{equation}\n",
    "\n",
    "5. Repeat steps 2-4 until the difference in $T$ between successive iterations is less than a predefined parameter $T_0$.\n",
    "\n",
    "Apply your function to the image <tt>fingerprint.jpg</tt>. Analyze your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that uses the $k$-means algorithm to perform image segmentation using RGB pixel colors as features.\n",
    "Write also a variant of this segmentation approach that uses the H and S components of each pixel represented in the HSI color space. Here, you should use normalized H and S values, so that both variables range between 0 and 1.\n",
    "Apply your functions to the image <tt>mms.jpg</tt>. Select an appropriate value of $k$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
